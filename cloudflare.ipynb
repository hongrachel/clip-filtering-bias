{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b42104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install IP2Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf24988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from langdetect import detect\n",
    "from iso639 import languages\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "from plotly.subplots import make_subplots\n",
    "import scipy\n",
    "\n",
    "import time\n",
    "import socket\n",
    "import requests\n",
    "import CloudFlare\n",
    "import IP2Location\n",
    "\n",
    "# Set notebook mode to work in offline\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from tldextract import extract\n",
    "import matplotlib.cm as cm\n",
    "  \n",
    "import urllib.request as urlopen\n",
    "from textwrap import wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ffa0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(filter_num, raw_num):\n",
    "    pos_list = [1] * filter_num\n",
    "    neg_list = [0] * (raw_num - filter_num)\n",
    "    err = np.std(pos_list + neg_list)\n",
    "    return err / np.sqrt(raw_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a236bf47",
   "metadata": {},
   "source": [
    "# Load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c55736",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/datacomp/'\n",
    "scale_dir = os.path.join(data_dir, 'small')\n",
    "metadata_dir = os.path.join(scale_dir, 'metadata')\n",
    "sample_image_dir = 'sample_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec783b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "for filename in os.listdir(metadata_dir):\n",
    "    filepath = os.path.join(metadata_dir, filename)\n",
    "    file_df = pd.read_parquet(filepath, engine='pyarrow')\n",
    "    if df is None:\n",
    "        df = file_df\n",
    "    else:\n",
    "        df = pd.concat([df, file_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eb104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l14_scores = df['clip_l14_similarity_score'].tolist()\n",
    "min_threshold = np.percentile(l14_scores, 70)\n",
    "print(min_threshold)\n",
    "filtered_df = df[df['clip_l14_similarity_score'] > min_threshold]\n",
    "excluded_df = df[df['clip_l14_similarity_score'] <= min_threshold]\n",
    "\n",
    "assert(len(filtered_df) + len(excluded_df) == len(df))\n",
    "print(len(df), len(filtered_df)) # 12.8M --> 3.94M filtered\n",
    "print(len(filtered_df) / len(df)) # 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9538af44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_kept'] = df['clip_l14_similarity_score'].apply(lambda x: x > min_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5618f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_captions = df['text'].tolist()\n",
    "filtered_captions = filtered_df['text'].tolist()\n",
    "excluded_captions = excluded_df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef8444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_urls = df['url'].tolist()\n",
    "filtered_urls = filtered_df['url'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0115bbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "def get_base_url(url):\n",
    "    extract_url = extract(url)\n",
    "    base = extract_url.domain\n",
    "    suffix = extract_url.suffix\n",
    "    return base + '.' + suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7d4dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['base_url'] = df['url'].apply(get_base_url)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671ac1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94ff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.read_parquet('df_sample_1M.parquet')\n",
    "df_sample['base_url'] = df_sample['url'].apply(get_base_url)\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7958456",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_uid_to_text = {}\n",
    "for _, row in df_sample.iterrows():\n",
    "    sample_uid_to_text[row['uid']] = row['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeec6e2",
   "metadata": {},
   "source": [
    "# Cloudflare categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ebc122",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id = 'XXX'\n",
    "api_url = 'https://api.cloudflare.com/client/v4/accounts/' + account_id + '/intel/domain/bulk'\n",
    "headers = {\n",
    "    \"X-Auth-Email\": \"XXX\",\n",
    "    \"X-Auth-Key\": \"XXX\"\n",
    "}\n",
    "\n",
    "outdir = '/data/datacomp/small/cloudflare_100k/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c9ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories(url_batch, start, end, r=None, outfile_name=None):    \n",
    "    if r is None:\n",
    "        r = requests.get(\n",
    "            api_url,\n",
    "            params={'domain': url_batch},\n",
    "            headers=headers,\n",
    "            stream=True,\n",
    "            timeout=300\n",
    "        )\n",
    "\n",
    "    if r.status_code == 200:\n",
    "        r_json = r.json()\n",
    "        \n",
    "        if outfile_name is None:\n",
    "            outfile_name = os.path.join(outdir, str(start) + '_' + str(end) + '.json')\n",
    "        with open(outfile_name, 'w') as f:\n",
    "            json.dump(r_json, f)\n",
    "    else:\n",
    "        print(end, 'request error', r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f44bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_urls = list(df_sample['base_url'].unique())\n",
    "len(base_urls), base_urls[:10]\n",
    "\n",
    "NUM_SAMPLE = 100000\n",
    "random.seed(0)\n",
    "sample_base_urls = random.sample(base_urls, NUM_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944788f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BATCH = 10\n",
    "start_batch_i = 1\n",
    "\n",
    "for batch_i in range(start_batch_i, int(len(sample_base_urls) / NUM_BATCH) + 1):\n",
    "    start = NUM_BATCH * batch_i\n",
    "    end = NUM_BATCH * (batch_i + 1)\n",
    "    print('categorizing for batch', batch_i, 'with entries i=', start, end)\n",
    "    \n",
    "    url_batch = sample_base_urls[start: end]\n",
    "    \n",
    "    try:\n",
    "        get_categories(url_batch, start, end)\n",
    "    except Exception as e:\n",
    "        print(end, 'ERROR', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494dff8b",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cbf2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_to_content_categories = {}\n",
    "for file in os.listdir(outdir):\n",
    "    filepath = os.path.join(outdir, file)\n",
    "    if filepath.endswith('.json'):\n",
    "        with open(filepath) as f:\n",
    "            r_json = json.load(f)\n",
    "            if 'success' in r_json and r_json['success'] and 'result' in r_json and r_json['result'] is not None:\n",
    "                for result in r_json['result']:\n",
    "                    if 'content_categories' in result:\n",
    "                        url_to_content_categories[result['domain']] = result['content_categories']\n",
    "            else:\n",
    "                print(filepath, 'json error')\n",
    "\n",
    "print(len(url_to_content_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94254263",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_to_categories = defaultdict(list)\n",
    "\n",
    "for url in url_to_content_categories:\n",
    "    for category in url_to_content_categories[url]:\n",
    "        if 'super_category_id' in category and category['super_category_id'] != 15:\n",
    "            url_to_categories[url].append(category['name'])\n",
    "\n",
    "category_to_urls = defaultdict(list)\n",
    "for url in url_to_categories:\n",
    "    for category in url_to_categories[url]:\n",
    "        category_to_urls[category].append(url)\n",
    "print(len(category_to_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76621ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_to_categories = {}\n",
    "for _, row in df_sample.iterrows():\n",
    "    uid = row['uid']\n",
    "    base_url = row['base_url']\n",
    "    if base_url in url_to_categories:\n",
    "        uid_to_categories[uid] = url_to_categories[base_url]\n",
    "\n",
    "print(len(uid_to_categories))\n",
    "df_sample['categories'] = df_sample['uid'].map(uid_to_categories)\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76483eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_filtered = df_sample[df_sample['is_kept'] == True]\n",
    "filtered_uids = set(df_sample_filtered['uid'].unique())\n",
    "\n",
    "categories_to_uid = defaultdict(lambda: defaultdict(list)) # category: {kept: [], total: []}\n",
    "\n",
    "for uid in uid_to_categories:\n",
    "    is_filtered = uid in filtered_uids\n",
    "    for category in uid_to_categories[uid]:\n",
    "        if is_filtered:\n",
    "            categories_to_uid[category]['kept'].append(uid)\n",
    "        categories_to_uid[category]['total'].append(uid)\n",
    "print(len(categories_to_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7f052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY_MAP = {\n",
    "    'APIs': 'Technology', # prior\n",
    "    'Adult Themes': 'NSFW', # NSFW\n",
    "    'Advertisements': 'Advertisements', # inaccurate\n",
    "    'Alcohol': 'Drugs & Alcohol', # new\n",
    "    'Artificial Intelligence': 'Technology', # new\n",
    "#     'Arts': 'Arts', \n",
    "#     'Arts & Crafts': 'Arts & Crafts', \n",
    "#     'Astrology': 'Astrology', \n",
    "#     'Auctions & Marketplaces': 'Auctions & Marketplaces',\n",
    "#     'Audio Streaming': 'Audio Streaming', \n",
    "#     'Body Art': 'Body Art', \n",
    "#     'Business': 'Business', \n",
    "    'CIPA Filter': 'NSFW', # NSFW\n",
    "#     'Cartoons & Anime': 'Cartoons & Anime', \n",
    "    'Chat': 'Chat & Messaging', # prior\n",
    "    'Clothing': 'Clothing & Fashion', # prior\n",
    "#     'Comic Books': 'Comic Books', \n",
    "    'Content Servers': 'Content Servers', # diff\n",
    "#     'Coupons': 'Coupons', \n",
    "    'Cryptocurrency': 'Cryptocurrency', # new\n",
    "#     'Dating & Relationships': 'Dating & Relationships', \n",
    "    'Deceptive Ads': 'Deceptive Ads', # inaccurate\n",
    "#     'Digital Postcards': 'Digital Postcards', \n",
    "    'Drugs': 'Drugs & Alcohol', # diff\n",
    "#     'Ecommerce': 'Ecommerce', \n",
    "#     'Economy & Finance': 'Economy & Finance', \n",
    "#     'Education': 'Education', \n",
    "#     'Educational Institutions': 'Educational Institutions', \n",
    "#     'Entertainment': 'Entertainment', \n",
    "    'Fashion': 'Clothing & Fashion', # prior\n",
    "    'File Sharing': 'File Sharing', # inaccurate\n",
    "    'Fine Art': 'Arts', # prior\n",
    "#     'Food & Drink': 'Food & Drink', \n",
    "#     'Forums': 'Forums', \n",
    "#     'Gambling': 'Gambling', \n",
    "#     'Gaming': 'Gaming', \n",
    "    'Government': 'Government & Politics', # prior\n",
    "#     'Hacking': 'Hacking', \n",
    "#     'Health & Fitness': 'Health & Fitness', \n",
    "#     'Hobbies & Interests': 'Hobbies & Interests', \n",
    "#     'Home & Garden': 'Home & Garden', \n",
    "    'Home Video/DVD': 'Movies & Home Video', # prior\n",
    "    'Humor': 'Humor', # inaccurate\n",
    "    'Information Security': 'Technology', # prior\n",
    "    'Information Technology': 'Technology', # prior \n",
    "    'Instant Messengers': 'Chat & Messaging', # prior\n",
    "    'Internet Phone & VOIP': 'Internet Phone & VOIP', # inaccurate\n",
    "#     'Job Search & Careers': 'Job Search & Careers', \n",
    "#     'Lifestyle': 'Lifestyle', \n",
    "    'Lingerie & Bikini': 'Clothing & Fashion', # prior\n",
    "#     'Magazines': 'Magazines', \n",
    "    'Messaging': 'Chat & Messaging', # prior\n",
    "    'Militancy, Hate & Extremism': 'NSFW', # inaccurate, NSFW\n",
    "    'Military': 'Government & Politics', # prior\n",
    "    'Movies': 'Movies & Home Video', \n",
    "#     'Music': 'Music', \n",
    "#     'News & Media': 'News & Media', \n",
    "    'News, Portal & Search': 'Stock Photos', # new\n",
    "    'Nudity': 'NSFW', # NSFW\n",
    "    'P2P': 'Video Streaming', # prior\n",
    "#     'Paranormal': 'Paranormal', \n",
    "#     'Parenting': 'Parenting', \n",
    "    'Personal Blogs': 'Personal Blogs', # inaccurate\n",
    "#     'Pets': 'Pets', \n",
    "    'Photo Sharing': 'File Sharing', # new\n",
    "#     'Photography': 'Photography', \n",
    "    'Politics, Advocacy, and Government-Related': 'Government & Politics', # diff\n",
    "    'Pornography': 'NSFW', # NSFW\n",
    "    'Professional Networking': 'Business', # prior\n",
    "#     'Questionable Activities': 'Questionable Activities', \n",
    "    'Radio': 'Audio Streaming', # prior\n",
    "#     'Real Estate': 'Real Estate', \n",
    "#     'Religion': 'Religion', \n",
    "#     'Safe for Kids': 'Safe for Kids', \n",
    "    'School Cheating': 'School Cheating', # new \n",
    "#     'Science': 'Science', \n",
    "    'Search Engines': 'Search Engines', # inaccurate\n",
    "#     'Sex Education': 'Sex Education', \n",
    "    'Shopping': 'Shopping', # inaccurate\n",
    "    'Social Networks': 'Social Networks', # inaccurate\n",
    "    'Space & Astronomy': 'Science', # prior \n",
    "#     'Sports': 'Sports', \n",
    "    'Swimsuits': 'Clothing & Fashion', # inaccurate\n",
    "#     'Technology': 'Technology', \n",
    "#     'Television': 'Television', \n",
    "    'Tobacco': 'Drugs & Alcohol', # diff\n",
    "    'Translator': 'Translator', # inaccurate\n",
    "#     'Travel': 'Travel', \n",
    "#     'Vehicles': 'Vehicles', \n",
    "#     'Video Streaming': 'Video Streaming', \n",
    "    'Violence': 'NSFW', \n",
    "    'Weapons': 'NSFW', \n",
    "#     'Weather': 'Weather', \n",
    "#     'Webmail': 'Webmail', \n",
    "}\n",
    "\n",
    "with open('cloudfare_categories.json', 'w') as f:\n",
    "    json.dump(CATEGORY_MAP, f)\n",
    "\n",
    "CATEGORY_MAP_REVERSE = defaultdict(list)\n",
    "for c in CATEGORY_MAP:\n",
    "    CATEGORY_MAP_REVERSE[CATEGORY_MAP[c]].append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675fa338",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in CATEGORY_MAP_REVERSE:\n",
    "    print(v, '&', '; '.join(CATEGORY_MAP_REVERSE[v]), r\"\\ \"[0] + r\"\\ \"[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6146b0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_categories_to_uid = defaultdict(lambda: defaultdict(list)) # category: {kept: [], total: []}\n",
    "\n",
    "for c in categories_to_uid:\n",
    "    if c in CATEGORY_MAP:\n",
    "        new_c = CATEGORY_MAP[c]\n",
    "        kept_uids = set(final_categories_to_uid[new_c]['kept'] + categories_to_uid[c]['kept'])\n",
    "        final_categories_to_uid[new_c]['kept'] = list(kept_uids)\n",
    "        total_uids = set(final_categories_to_uid[new_c]['total'] + categories_to_uid[c]['total'])\n",
    "        final_categories_to_uid[new_c]['total'] = list(total_uids)\n",
    "    else:\n",
    "        final_categories_to_uid[c]['kept'] = categories_to_uid[c]['kept']\n",
    "        final_categories_to_uid[c]['total'] = categories_to_uid[c]['total']\n",
    "print(len(categories_to_uid), len(final_categories_to_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dee285e",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3cf44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_count_by_category = {}\n",
    "ratios_by_category = {}\n",
    "for c in final_categories_to_uid:\n",
    "    num_total = len(final_categories_to_uid[c]['total'])\n",
    "    raw_count_by_category[c] = num_total\n",
    "    if num_total > 1000:\n",
    "        ratio = len(final_categories_to_uid[c]['kept']) / num_total\n",
    "        ratios_by_category[c] = ratio\n",
    "print(len(ratios_by_category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e3c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw count\n",
    "\n",
    "top_num = 20\n",
    "sorted_count_by_category = {k: v for k, v in sorted(\n",
    "    raw_count_by_category.items(), key=lambda item: item[1], reverse=True\n",
    ") if v > 1000}\n",
    "\n",
    "plot_df = pd.DataFrame({\n",
    "    'category': list(sorted_count_by_category.keys()),\n",
    "    'count': list(sorted_count_by_category.values())\n",
    "})\n",
    "plot_df.sort_values('count', ascending=False).plot(\n",
    "    kind='bar',y='count',x='category', figsize=(15, 2), legend=False\n",
    ")\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=40, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d5ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(list(sorted_count_by_category.values())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e1cd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in list(sorted_count_by_category.keys()):\n",
    "    print(c, '|', sorted_count_by_category[c])\n",
    "# for c in list(sorted_count_by_category.keys())[-top_num:]:\n",
    "#     print(c, '|', sorted_count_by_category[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e7cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter ratios\n",
    "\n",
    "sorted_ratios_by_category = {k: v for k, v in sorted(\n",
    "    ratios_by_category.items(), key=lambda item: item[1], reverse=True\n",
    ")}\n",
    "yerr = [\n",
    "    get_error(\n",
    "        len(final_categories_to_uid[c]['kept']),\n",
    "        len(final_categories_to_uid[c]['total'])\n",
    "    )\n",
    "    for c in sorted_ratios_by_category\n",
    "]\n",
    "results_df = pd.DataFrame({\n",
    "    'top_category': list(sorted_ratios_by_category.keys()),\n",
    "    'Category filter ratio': list(sorted_ratios_by_category.values()),\n",
    "    'top_yerr': yerr,\n",
    "#     'bottom_category': list(sorted_ratios_by_category.keys()),\n",
    "#     'bottom_ratio': list(sorted_ratios_by_category.values()),\n",
    "#     'bottom_yerr': yerr,\n",
    "})\n",
    "results_df.sort_values('Category filter ratio', ascending=False).plot(\n",
    "    kind='bar',y='Category filter ratio',x='top_category',xerr='top_yerr',\n",
    "    figsize=(15, 2), legend=False\n",
    ")\n",
    "plt.ylabel('Filter ratio')\n",
    "plt.xlabel('')\n",
    "plt.xticks(rotation=40, ha='right')\n",
    "plt.axhline(y=0.3, color='r', linestyle='-', label='Global filter ratio')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed9835",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in list(sorted_ratios_by_category.keys())[:top_num]:\n",
    "    print(c, ';', sorted_ratios_by_category[c])\n",
    "for c in list(sorted_ratios_by_category.keys())[-top_num:]:\n",
    "    print(c, ';', sorted_ratios_by_category[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter ratios by category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ed32a6",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95054586",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in sorted(category_to_urls.keys()):\n",
    "    print(\"'\" + k + \"'\" + ', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cbea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsfw_uids = final_categories_to_uid['NSFW']['kept']\n",
    "print(len(nsfw_uids))\n",
    "# df_sample[df_sample['uid'].isin(set(nsfw_uids))][['uid', 'base_url', 'is_kept', 'text', 'categories']].to_csv('nsfw_uids.csv', escapechar='\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eec3ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 'Politics, Advocacy, and Government-Related'\n",
    "category_to_urls[c], len(categories_to_uid[c]['kept']), len(categories_to_uid[c]['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c798bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_urls = ['wp.com', 'pinimg.com', 'ebayimg.com', 'cloudfront.net', 'wordpress.com', 'wixstatic.com', 'made-in-china.com', 'ssl-images-amazon.com', 'amazonaws.com', 'alicdn.com', 'gstatic.com', 'fc2.com', 'media-amazon.com', 'gravatar.com', 'ytimg.com', 'tripadvisor.com', 'ebaystatic.com', 'bing.net', 'exblog.jp', 'dreamstime.com']\n",
    "sample_urls = ['s6img.com', 'shutterstock.com', 'cpcache.com', 'shopstyle-cdn.com', 'bigstockphoto.com', 'vectorstock.com', 'canstockphoto.com', 'fineartamerica.com', 'gettyimages.com', 'etsystatic.com', 'photoshelter.com', 'bing.net', 'zcache.com', 'shoplightspeed.com', '123rf.com', 'slideserve.com', 'teacherspayteachers.com', 'ftcdn.net', 'ssl-images-amazon.com', 'ztat.net'] \\\n",
    "    + ['canalblog.com', 'prom.st', 'userapi.com', 'servimg.com', 'ebaystatic.com', 'wklcdn.com', 'rightmove.co.uk', 'k-img.com', 'goo-net.com', 'sinaimg.cn', 'seesaa.net', 'blogimg.jp', 'st-hatena.com', 'pimg.tw', 'fc2.com', 'cocolog-nifty.com', 'wikidot.com', 'exblog.jp', 'gravatar.com', 'buuyers.com']\n",
    "print(len(sample_urls))\n",
    "\n",
    "get_categories(sample_urls[:10], 0, 0, outfile_name='cloudflare_domains/top_domains_3.json')\n",
    "get_categories(sample_urls[10:20], 0, 0, outfile_name='cloudflare_domains/top_domains_4.json')\n",
    "get_categories(sample_urls[20:30], 0, 0, outfile_name='cloudflare_domains/top_domains_5.json')\n",
    "get_categories(sample_urls[30:40], 0, 0, outfile_name='cloudflare_domains/top_domains_6.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a551b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_url_to_content_categories = {}\n",
    "for file in os.listdir('cloudflare_domains/'):\n",
    "    filepath = os.path.join('cloudflare_domains/', file)\n",
    "    if filepath.endswith('.json'):\n",
    "        with open(filepath) as f:\n",
    "            r_json = json.load(f)\n",
    "            if 'success' in r_json and r_json['success'] and 'result' in r_json and r_json['result'] is not None:\n",
    "                for result in r_json['result']:\n",
    "                    if 'content_categories' in result:\n",
    "                        sample_url_to_content_categories[result['domain']] = result['content_categories']\n",
    "            else:\n",
    "                print(filepath, 'json error')\n",
    "\n",
    "sample_url_to_categories = defaultdict(list)\n",
    "\n",
    "for url in sample_url_to_content_categories:\n",
    "    for category in sample_url_to_content_categories[url]:\n",
    "        if 'super_category_id' in category and category['super_category_id'] != 15:\n",
    "            sample_url_to_categories[url].append(category['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04025c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in sample_urls:\n",
    "    print(url, sample_url_to_categories[url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f4e76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(url_to_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224121df",
   "metadata": {},
   "source": [
    "# IP Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1428d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set([row[3] for row in rows]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702729ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_url_to_ip = {}\n",
    "\n",
    "for row in rows:\n",
    "    uid = row[1]\n",
    "    url = row[2]\n",
    "    base_url = row[3]\n",
    "    \n",
    "    if base_url in base_url_to_ip:\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        ip_addr = socket.gethostbyname(base_url)\n",
    "#         print(uid, base_url, ip_addr)\n",
    "        base_url_to_ip[base_url] = ip_addr\n",
    "    except Exception as e:\n",
    "        base_url_to_ip[base_url] = None\n",
    "        print('ERROR', base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e840d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('base_url_200k_to_ip.json', 'w') as fp:\n",
    "    json.dump(base_url_to_ip, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162e244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([u for u in base_url_to_ip if base_url_to_ip[u] is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72638fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map ip address to country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cf8f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_db_path = \"../scripts/ip2location_db/IP2LOCATION-LITE-DB1.IPV6.BIN\"\n",
    "ip_db = IP2Location.IP2Location(ip_db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219cd750",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = ip_db.get_all(\"19.5.10.1\")\n",
    "rec.country_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b87b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url_to_country_code = {}\n",
    "base_url_to_country_name = {}\n",
    "for base_url in base_url_to_ip:\n",
    "    ip = base_url_to_ip[base_url]\n",
    "    if ip is not None:\n",
    "        rec = ip_db.get_all(ip)\n",
    "        base_url_to_country_name[base_url] = rec.country_long\n",
    "        base_url_to_country_code[base_url] = rec.country_short\n",
    "#         print(base_url, country)\n",
    "    else:\n",
    "        base_url_to_country_code[base_url] = None\n",
    "        base_url_to_country_name[base_url] = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374b2c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([u for u in base_url_to_country_code if base_url_to_country_code[u] is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3620d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('base_url_200k_to_country_code.json', 'w') as fp:\n",
    "#     json.dump(base_url_to_country_code, fp)\n",
    "# with open('base_url_200k_to_country_name.json', 'w') as fp:\n",
    "#     json.dump(base_url_to_country_name, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb2b887",
   "metadata": {},
   "source": [
    "## analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79c52f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('base_url_200k_to_country_name.json') as f:\n",
    "    base_url_to_country_name = json.load(f)\n",
    "len(base_url_to_country_name), len([c for c in base_url_to_country_name if base_url_to_country_name[c] is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3089c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_to_base_url = {}\n",
    "for _, row in df_sample.iterrows():\n",
    "    uid_to_base_url[row['uid']] = row['base_url']\n",
    "len(uid_to_base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13899a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count by country in filtered dataset\n",
    "\n",
    "df_sample_filtered = df_sample[df_sample['is_kept'] == True]\n",
    "filtered_uids = df_sample_filtered['uid'].tolist()\n",
    "\n",
    "count_by_country = defaultdict(int)\n",
    "succ_count = 0\n",
    "err_count = 0\n",
    "\n",
    "for uid in df_sample['uid'].tolist():\n",
    "    base_url = uid_to_base_url[uid]\n",
    "    if base_url in base_url_to_country_name:\n",
    "        country = base_url_to_country_name[base_url]\n",
    "        if country is not None and country != '-':\n",
    "            count_by_country[country] += 1\n",
    "            succ_count += 1\n",
    "        else:\n",
    "            err_count += 1\n",
    "    else:\n",
    "        err_count += 1\n",
    "print(succ_count, err_count, succ_count / (succ_count + err_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba8ceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTRIES = ['Netherlands', 'United Kingdom', 'Iran', 'Korea', 'Taiwan', 'Virgin Islands']\n",
    "def parse_country(name):\n",
    "    country = name\n",
    "    if name == 'United States of America':\n",
    "        country = 'USA'\n",
    "    elif name == 'Russian Federation':\n",
    "        country = 'Russia'\n",
    "    else:\n",
    "        for c in COUNTRIES:\n",
    "            if name.startswith(c):\n",
    "                country = c\n",
    "    return country\n",
    "\n",
    "top_num = 20\n",
    "sorted_count_by_country = {parse_country(k): v for k, v in sorted(\n",
    "    count_by_country.items(), key=lambda item: item[1], reverse=True\n",
    ")}\n",
    "\n",
    "plot_df = pd.DataFrame({\n",
    "    'country': list(sorted_count_by_country.keys())[:top_num],\n",
    "    'count': list(sorted_count_by_country.values())[:top_num]\n",
    "})\n",
    "plot_df.sort_values('count').plot(kind='barh',y='count',x='country')\n",
    "plt.xlabel('IP address geolocation breakdown by country in raw dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6726319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in list(sorted_count_by_country.keys())[:top_num]:\n",
    "    print(c, sorted_count_by_country[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eeb6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "pattern = re.compile(r'[^A-Za-z ]+')\n",
    "\n",
    "def clean_caption(caption, as_set=False):\n",
    "    # only return unique words in caption\n",
    "    cleaned_caption = pattern.sub(' ', caption.lower())\n",
    "    if as_set:\n",
    "        return set(cleaned_caption.split(' '))\n",
    "    else:\n",
    "        return cleaned_caption\n",
    "\n",
    "def is_english(uid):\n",
    "    caption = sample_uid_to_text[uid]\n",
    "    cleaned_caption = clean_caption(caption)\n",
    "    if cleaned_caption.strip() != '':\n",
    "        try:\n",
    "            lang = detect(cleaned_caption)\n",
    "            if lang == 'en':\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            # print(e, caption)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2b5c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter ratio by country\n",
    "uid_by_country = defaultdict(lambda: defaultdict(list)) # {country: {'kept': [], 'total': []}}\n",
    "filtered_uids_set = set(filtered_uids)\n",
    "\n",
    "succ_count = 0\n",
    "\n",
    "for uid in df_sample['uid'].tolist():\n",
    "    is_kept = uid in filtered_uids_set\n",
    "    base_url = uid_to_base_url[uid]\n",
    "    country = base_url_to_country_name[base_url] if base_url in base_url_to_country_name else None\n",
    "    if country is not None and country != '-':\n",
    "        if True: # is_english(uid):\n",
    "            uid_by_country[country]['total'].append(uid)\n",
    "            if is_kept:\n",
    "                uid_by_country[country]['kept'].append(uid)\n",
    "            succ_count += 1\n",
    "\n",
    "err_count = len(df_sample) - succ_count\n",
    "print(succ_count, err_count, succ_count / (succ_count + err_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2458e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(succ_count, err_count, succ_count / (succ_count + err_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3cad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = uid_by_country.keys()\n",
    "raw_count_by_country = {}\n",
    "ratios_by_country = {}\n",
    "for c in countries:\n",
    "    num_total = len(uid_by_country[c]['total'])\n",
    "    if num_total > 5000:\n",
    "        ratio = len(uid_by_country[c]['kept']) / num_total\n",
    "        ratios_by_country[c] = (ratio)\n",
    "        raw_count_by_country[c] = num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d924865",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in raw_count_by_country:\n",
    "    print(c, ',', raw_count_by_country[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8466424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ratios_by_country = {(k): v for k, v in sorted(\n",
    "    ratios_by_country.items(), key=lambda item: item[1], reverse=True\n",
    ")}\n",
    "yerr = [\n",
    "    get_error(\n",
    "        len(uid_by_country[c]['kept']),\n",
    "        len(uid_by_country[c]['total'])\n",
    "    )\n",
    "    for c in sorted_ratios_by_country\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 3))\n",
    "results_df = pd.DataFrame({\n",
    "    'top_country': [parse_country(c) for c in sorted_ratios_by_country.keys()],\n",
    "    'top_ratio': list(sorted_ratios_by_country.values()),\n",
    "    'top_yerr': yerr,\n",
    "})\n",
    "results_df.sort_values('top_ratio', ascending=False).plot(\n",
    "    kind='bar',y='top_ratio',x='top_country',yerr='top_yerr', legend=False,ax=ax\n",
    ")\n",
    "ax.set_ylabel('Filter ratio')\n",
    "ax.set_xlabel('')\n",
    "ax.set_xticks(np.arange(len(sorted_ratios_by_country)), labels=results_df['top_country'], rotation=40, ha='right')\n",
    "\n",
    "nonwest_is = [0, 10, 12, 13, 14, 15, 16]\n",
    "for i in nonwest_is:\n",
    "    label = ax.get_xticklabels()[i]\n",
    "    label.set_bbox(dict(facecolor='yellow', edgecolor='yellow', pad=0))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a5539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar graph: AGE and GENDER\n",
    "\n",
    "graph_results = defaultdict(list)\n",
    "\n",
    "for c in sorted_ratios_by_country:\n",
    "    total_num = len(uid_by_country[c]['total'])\n",
    "    filter_num = len(uid_by_country[c]['kept'])\n",
    "    graph_results['kept'].append(filter_num)\n",
    "    graph_results['excluded'].append(total_num - filter_num)\n",
    "\n",
    "x = np.arange(len(sorted_ratios_by_country))  # the label locations\n",
    "labels = ['%s (%.2f)' % (parse_country(c), sorted_ratios_by_country[c]) for c in sorted_ratios_by_country]\n",
    "\n",
    "width = 0.5  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "bottom = np.zeros(len(x))\n",
    "\n",
    "for k, v in graph_results.items():\n",
    "    rects = ax.bar(x + width/2, v, width, label=k, bottom=bottom, hatch='///' if k == 'kept' else None)\n",
    "#         ax.bar_label(rects) # , padding=3)\n",
    "    bottom += v\n",
    "\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Frequency by geolocation for English-detected samples')\n",
    "ax.legend(loc='upper right', ncols=1)\n",
    "ax.set_xticks(x + width/2, labels=labels, rotation=40, ha='right')\n",
    "ax.tick_params(axis='x', which='major', pad=0)\n",
    "\n",
    "nonwest_is = [0, 10, 13, 14, 15, 16]\n",
    "for i in nonwest_is:\n",
    "    label = ax.get_xticklabels()[i]\n",
    "    label.set_bbox(dict(facecolor='yellow', edgecolor='yellow', pad=0))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4064ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in (list(sorted_ratios_by_country.keys())):\n",
    "    print(c, ',', sorted_ratios_by_country[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9179293",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_num = 20\n",
    "sorted_count_by_country = {k: v for k, v in sorted(\n",
    "    count_by_country.items(), key=lambda item: len(item[1]), reverse=True\n",
    ")}\n",
    "\n",
    "plot_df = pd.DataFrame({\n",
    "    'country': list(count_by_country.keys())[:top_num],\n",
    "    'count': list(count_by_country.values())[:top_num]\n",
    "})\n",
    "plot_df.sort_values('count').plot(kind='barh',y='count',x='country')\n",
    "plt.xlabel('Country breakdown in kept dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028534b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_COUNT = 1000\n",
    "x = [raw_count_by_country[c] for c in raw_count_by_country if raw_count_by_country[c] >= MIN_COUNT]\n",
    "y = [filter_ratios[c] for c in raw_count_by_country if raw_count_by_country[c] >= MIN_COUNT]\n",
    "\n",
    "plt.xlabel('Raw count by year')\n",
    "plt.ylabel('Filter ratio (percent in kept dataset)') \n",
    "plt.title('Filter ratio vs frequency in unfiltered dataset')\n",
    "plt.scatter(x, y)\n",
    "\n",
    "b, a = np.polyfit(x, y, deg=1)\n",
    "print(np.corrcoef(x, y)[0,1] ** 2)\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(x, y)\n",
    "print(slope, intercept, r_value, p_value, std_err)\n",
    "# Create sequence of 100 numbers from 0 to 100 \n",
    "xseq = np.linspace(0, 30000, num=100)\n",
    "\n",
    "# Plot regression line\n",
    "plt.plot(xseq, a + b * xseq, color=\"k\", lw=2.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b003dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
